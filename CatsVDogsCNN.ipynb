{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries needed for data cleaning & dataset construction:\n",
    "import os\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign filepaths as strings objects for convenience:\n",
    "cat_dir = '/Users/JackLi/Downloads/Cats_and_Dogs_Data/PetImages/Cat'\n",
    "dog_dir = '/Users/JackLi/Downloads/Cats_and_Dogs_Data/PetImages/Dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12469/12469 [01:34<00:00, 132.13it/s]\n",
      "  0%|          | 0/12464 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-images removed from cats:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12464/12464 [01:51<00:00, 111.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of non-images removed from dogs:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Remove non-image files:\n",
    "c = 0\n",
    "d = 0\n",
    "for file in tqdm(os.listdir(cat_dir)):\n",
    "    path = os.path.join(cat_dir, file)\n",
    "    try: \n",
    "        io.imread(path)\n",
    "    except Exception as e:\n",
    "        os.remove(path)\n",
    "        c += 1\n",
    "print('# of non-images removed from cats: ', c)\n",
    "\n",
    "for file in tqdm(os.listdir(dog_dir)):\n",
    "    path = os.path.join(dog_dir, file)\n",
    "    try: \n",
    "        io.imread(path)\n",
    "    except Exception as e:\n",
    "        os.remove(path)\n",
    "        d += 1\n",
    "print('# of non-images removed from dogs: ', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12469/12469 [01:27<00:00, 141.91it/s]\n",
      "100%|██████████| 12464/12464 [01:00<00:00, 205.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of grayscale images removed from both:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Remove grayscale images:\n",
    "g = 0\n",
    "for file in tqdm(os.listdir(cat_dir)):\n",
    "    path = os.path.join(cat_dir, file)\n",
    "    image = io.imread(path)\n",
    "    if image.shape[2] == 3:\n",
    "        pass\n",
    "    else:\n",
    "        os.remove(path)\n",
    "        g += 1\n",
    "        \n",
    "for file in tqdm(os.listdir(dog_dir)):\n",
    "    path = os.path.join(dog_dir, file)\n",
    "    image = io.imread(path)\n",
    "    if image.shape[2] == 3:\n",
    "        pass\n",
    "    else:\n",
    "        os.remove(path)\n",
    "        g += 1\n",
    "\n",
    "print('# of grayscale images removed from both: ', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset class & overwrite __init__, __len__, and __getitem__ functions:\n",
    "class CVD(Dataset):\n",
    "    def __init__(self, cat_dir, dog_dir, transform = None):\n",
    "        self.cat_dir = cat_dir\n",
    "        self.dog_dir = dog_dir\n",
    "        self.transform = transform\n",
    "        self.cat_img = os.listdir(cat_dir)\n",
    "        self.dog_img = os.listdir(dog_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        length = len(self.cat_img) + len(self.dog_img)\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            cat = False\n",
    "            dog = False\n",
    "            \n",
    "            if torch.is_tensor(idx):\n",
    "                idx = idx.to_list()\n",
    "            if idx <= len(self.cat_img) - 1:\n",
    "                idx = idx\n",
    "                cat = True\n",
    "                img_path = os.path.join(self.cat_dir, self.cat_img[idx])\n",
    "            elif idx > len(self.cat_img) - 1:\n",
    "                idx = idx - len(self.cat_img)\n",
    "                dog = True\n",
    "                img_path = os.path.join(self.dog_dir, self.dog_img[idx])\n",
    "\n",
    "            image = io.imread(img_path)\n",
    "\n",
    "            if cat == True:\n",
    "                classification = 1\n",
    "            elif dog == True:\n",
    "                classification = 0\n",
    "\n",
    "            sample = {'image': image, 'classification': classification}\n",
    "\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "\n",
    "            return sample\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Rescale class to rescale images\n",
    "class Rescale(object):\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        classification = sample['classification']\n",
    "        \n",
    "        ori_h, ori_w = image.shape[:2]\n",
    "        \n",
    "        if isinstance(self.output_size, tuple):\n",
    "            new_h, new_w = self.output_size\n",
    "        elif isinstance(self.output_size, int):\n",
    "            if ori_h > ori_w:\n",
    "                new_h = self.output_size * ori_h / ori_w\n",
    "                new_w = self.output_size\n",
    "            else:\n",
    "                new_h = self.output_size\n",
    "                new_w = self.output_size * ori_w / ori_h\n",
    "                \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "                \n",
    "        image = transform.resize(image, (new_h, new_w))\n",
    "        \n",
    "        return {'image': image, 'classification': classification}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ToTensor class to convert samples into tensors\n",
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        classification = sample['classification']\n",
    "        \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        return {'image' : torch.from_numpy(image), 'classification': classification}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create transformed_dataset\n",
    "transformed_dataset = CVD(cat_dir, dog_dir, transform = transforms.Compose([Rescale((128, 128)), ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 11868/24933 [05:12<05:40, 38.34it/s]"
     ]
    }
   ],
   "source": [
    "#Making sure transformed_dataset works\n",
    "count = {'True' : 0, 'False': 0}\n",
    "\n",
    "for i in tqdm(range(len(transformed_dataset))):\n",
    "        if transformed_dataset[i]:\n",
    "            count['True'] = count['True'] + 1\n",
    "        else:\n",
    "            count['False'] = count['False'] + 1\n",
    "print('functional: ', count['True'])\n",
    "print('dysfunctional: ', count['False'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "loaded = DataLoader(transformed_dataset, batch_size = 16, shuffle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
